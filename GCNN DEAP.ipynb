{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "from einops import reduce, rearrange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from npeet import entropy_estimators as ee\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Video with shape (32,7680)\n",
    "# Output: Graph node features with shape (60*32,5) -> 60 graphs with 32 electrodes each with 5 features each\n",
    "def process_video_de(video):\n",
    "    # Delta, Theta, Alpha, Beta, Gamma\n",
    "    bands = [(0,3),(4,7),(8,13),(14,30),(31,50)]\n",
    "    # Split into windows\n",
    "    video = video.reshape(-1,32,128)\n",
    "    node_features = []\n",
    "    # For each window with shape (32,128) \n",
    "    for window in video:\n",
    "        graph_features = []\n",
    "        # Get frequency bands and calculate DE for each band -> (32,5)\n",
    "        for channel in window:\n",
    "            # Transform to frequency domain\n",
    "            fft_vals = np.fft.rfft(channel)\n",
    "            fft_vals = np.abs(fft_vals)\n",
    "            # Get values for different bands and compute DE\n",
    "            de_features = [ee.entropy(fft_vals[f:t].reshape(-1,1), k=2) for f,t in bands]\n",
    "            graph_features.append(de_features)\n",
    "            \n",
    "        node_features.append(graph_features)\n",
    "    node_features = torch.FloatTensor(node_features).reshape(-1,5)\n",
    "    return node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import rfft, rfftfreq, ifft\n",
    "import scipy.signal\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Video with shape (32,7680)\n",
    "# Output: Graph node features with shape (59*32, 5) -> 59 graphs with 32 nodes each with 5 features each\n",
    "def process_video_psd(video):\n",
    "    # Delta, Theta, Alpha, Beta, Gamma\n",
    "    bands = [(0,4),(4,8),(8,12),(12,30),(30,45)]\n",
    "    # Split into windows\n",
    "    samplingFrequency = 128\n",
    "    psd_features = []\n",
    "    for channel in video:\n",
    "        # Transform to frequency domain\n",
    "        # Get real amplitudes of FFT (only in positive frequencies) ->rfft=real fast fourier transformation (on real inputs)\n",
    "        fft_vals = np.fft.rfft(channel)\n",
    "        # Get frequencies for amplitudes in Hz\n",
    "        fft_freq = np.fft.rfftfreq(len(channel), 1.0/samplingFrequency)\n",
    "        band_data = []\n",
    "        for f,t in bands:\n",
    "            mask = np.logical_or(fft_freq < f, fft_freq > t)\n",
    "            band = fft_vals.copy()\n",
    "            band[mask] = 0\n",
    "            band_data.append(band)\n",
    "        inverse = [np.fft.irfft(band) for band in band_data]\n",
    "        psds = []\n",
    "        for inv in inverse:\n",
    "            psd = []\n",
    "            idx = 0\n",
    "            while idx+256 <= len(inv):\n",
    "                a = scipy.signal.periodogram(inv[idx:idx+256])[1]\n",
    "                psd.append(a.mean())\n",
    "                idx += 128\n",
    "            psds.append(psd)\n",
    "            \n",
    "        psds = np.array(psds).transpose(1,0)\n",
    "        psd_features.append(psds)\n",
    "    psd_features = torch.FloatTensor(psd_features)\n",
    "    psd_features = rearrange(psd_features,'a b c -> (b a) c')\n",
    "    return psd_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data, DataLoader\n",
    "from Electrodes import Electrodes\n",
    "from tqdm import tqdm\n",
    "class DEAPDatasetEEGFeatures(InMemoryDataset):\n",
    "    \n",
    "  def __init__(self, root, raw_dir,processed_dir, transform=None, pre_transform=None,include_edge_attr = False, undirected_graphs = True, add_global_connections=True, participant_from=1, participant_to=32,window_size=128, n_videos=40):\n",
    "      self._raw_dir = raw_dir\n",
    "      self._processed_dir = processed_dir\n",
    "      self.participant_from = participant_from\n",
    "      self.participant_to = participant_to\n",
    "      self.n_videos = n_videos\n",
    "      self.window_size = window_size\n",
    "      # Whether or not to include edge_attr in the dataset\n",
    "      self.include_edge_attr = include_edge_attr\n",
    "      # If true there will be 1024 links as opposed to 528\n",
    "      self.undirected_graphs = undirected_graphs\n",
    "      # Instantiate class to handle electrode positions\n",
    "      print('Using global connections' if add_global_connections else 'Not using global connections')\n",
    "      self.electrodes = Electrodes(add_global_connections, expand_3d = False)\n",
    "      super(DEAPDatasetEEGFeatures, self).__init__(root, transform, pre_transform)\n",
    "      self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "      \n",
    "\n",
    "  @property\n",
    "  def raw_dir(self):\n",
    "      return f'{self.root}/{self._raw_dir}'\n",
    "\n",
    "  @property\n",
    "  def processed_dir(self):\n",
    "      return f'{self.root}/{self._processed_dir}'\n",
    "\n",
    "  @property\n",
    "  def raw_file_names(self):\n",
    "      raw_names = [f for f in os.listdir(self.raw_dir)]\n",
    "      raw_names.sort()\n",
    "      return raw_names\n",
    "\n",
    "  @property\n",
    "  def processed_file_names(self):\n",
    "      if not os.path.exists(self.processed_dir):\n",
    "        os.makedirs(self.processed_dir)\n",
    "      file_name = f'{self.participant_from}-{self.participant_to}' if self.participant_from is not self.participant_to else f'{self.participant_from}'\n",
    "      return [f'deap_processed_graph.{file_name}_psd.dataset']\n",
    "\n",
    "  def process(self):\n",
    "        # Number of nodes per graph\n",
    "        n_nodes = len(self.electrodes.positions_3d)\n",
    "\n",
    "        if self.undirected_graphs:\n",
    "            source_nodes, target_nodes = np.repeat(np.arange(0,n_nodes),n_nodes), np.tile(np.arange(0,n_nodes),n_nodes)\n",
    "        else:\n",
    "            source_nodes, target_nodes = np.tril_indices(n_nodes,n_nodes)\n",
    "        \n",
    "        edge_attr = self.electrodes.adjacency_matrix[source_nodes,target_nodes]\n",
    "        \n",
    "        # Remove zero weight links\n",
    "        mask = np.ma.masked_not_equal(edge_attr, 0).mask\n",
    "        edge_attr,source_nodes,target_nodes = edge_attr[mask], source_nodes[mask], target_nodes[mask]\n",
    "\n",
    "        edge_attr, edge_index = torch.FloatTensor(edge_attr), torch.tensor([source_nodes,target_nodes], dtype=torch.long)\n",
    "        \n",
    "        # Expand edge_index and edge_attr to match windows\n",
    "        e_edge_index = edge_index.clone()\n",
    "        e_edge_attr = edge_attr.clone()\n",
    "        for i in range(58):\n",
    "            a = edge_index + e_edge_index.max() + 1\n",
    "            e_edge_index = torch.cat([e_edge_index,a],dim=1)\n",
    "            e_edge_attr = torch.cat([e_edge_attr,edge_attr],dim=0)\n",
    "\n",
    "        print(e_edge_index)\n",
    "        # List of graphs that will be written to file\n",
    "        data_list = []\n",
    "        pbar = tqdm(range(self.participant_from,self.participant_to+1))\n",
    "        for participant_id in pbar:\n",
    "            raw_name = [e for e in self.raw_file_names if str(participant_id).zfill(2) in e][0]\n",
    "            pbar.set_description(raw_name)\n",
    "            # Load raw file as np array\n",
    "            participant_data = scipy.io.loadmat(f'{self.raw_dir}/{raw_name}')\n",
    "            signal_data = torch.FloatTensor(participant_data['data'][:,:32,128*3:])\n",
    "            processed = []\n",
    "            for i, video in enumerate(signal_data[:self.n_videos,:,:]):\n",
    "                \n",
    "                # Differential entropy for each band\n",
    "                # node_features = process_video_de(video)\n",
    "\n",
    "                # Power spectral density for each channel\n",
    "                # node_features = scipy.signal.periodogram(video)[1]\n",
    "                node_features = process_video_psd(video)\n",
    "                \n",
    "                # Raw signals \n",
    "                # node_features = video\n",
    "                \n",
    "                # Should we add MinMax/Z scaler?\n",
    "                data = Data(x=torch.FloatTensor(node_features),edge_attr=e_edge_attr,edge_index=e_edge_index, y=torch.FloatTensor([participant_data['labels'][i]])) if self.include_edge_attr else Data(x=torch.FloatTensor(node_features), edge_index=e_edge_index, y=torch.FloatTensor([participant_data['labels'][i]]))\n",
    "                data_list.append(data) \n",
    "               \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s01.mat:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global connections\n",
      "Processing...\n",
      "tensor([[   0,    0,    0,  ..., 1887, 1887, 1887],\n",
      "        [   0,    1,    2,  ..., 1877, 1881, 1887]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s32.mat: 100%|██████████| 32/32 [23:20<00:00, 43.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 11446], x=[1888, 5], y=[1, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants used to define data paths\n",
    "ROOT_DIR = './'\n",
    "RAW_DIR = 'data/matlabPREPROCESSED'\n",
    "PROCESSED_DIR = 'data/graphProcessedData'\n",
    "\n",
    "dataset = DEAPDatasetEEGFeatures(root= ROOT_DIR, raw_dir= RAW_DIR, processed_dir= PROCESSED_DIR)\n",
    "# Subject-independent classificati\n",
    "# DEPENDING ON WHAT DATA IS USED THE NETWORK LEARNS BETTER OR WORSE.\n",
    "# SHOULD WE TRY TO HAVE A BALANCEd TRAINING SET?\n",
    "dataset = dataset.shuffle()\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DEAPDatasetEEGFeatures(1100), DEAPDatasetEEGFeatures(180))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 880 used for training, 220 validation and 180 testing\n",
    "splt_idx = 1100\n",
    "# splt_idx = 35\n",
    "\n",
    "# 85% used for train/val\n",
    "train_dataset = dataset[:splt_idx]\n",
    "test_dataset = dataset[splt_idx:]\n",
    "\n",
    "train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 11446], x=[1888, 5], y=[1, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=64):\n",
    "        super(Model, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.gconv1 = GCNConv(in_channels, hidden_channels//2, aggr='add')\n",
    "        self.gconv2 = GCNConv(hidden_channels//2, hidden_channels, aggr='add')\n",
    "#         self.gconv3 = GCNConv(64, 1, aggr='add')\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(hidden_channels*59, hidden_channels*8, 1, stride=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_channels*8, hidden_channels, 1, stride=1)\n",
    "        \n",
    "        self.lin1 = nn.Linear(32*hidden_channels,32*4)\n",
    "        self.lin2 = nn.Linear(32*4,32)\n",
    "        self.lin3 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        bs = len(torch.unique(batch.batch))\n",
    "        x, edge_index = batch.x, batch.edge_index\n",
    "\n",
    "#         x = x.reshape(-1,self.in_channels)\n",
    "#         print(x.shape)\n",
    "        x = self.gconv1(x, edge_index)\n",
    "        x = torch.tanh(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "#         print(x.shape)\n",
    "#         raise 'err'\n",
    "        x = self.gconv2(x, edge_index)\n",
    "        x = torch.tanh(x)\n",
    "#         x = self.gconv3(x, edge_index)\n",
    "#         x = torch.tanh(x)\n",
    "        \n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = x.reshape(bs,-1,32)\n",
    "\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = x.reshape(bs,-1)\n",
    "        \n",
    "        x = self.lin1(x)\n",
    "        x.sigmoid()\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x.sigmoid()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "\n",
    "\n",
    "        return x.view(-1).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter count: 2235393\n",
      "Epoch 1 - Kfold:0 ;t loss: 0.70096 ;t acc: 0.53 ;v loss: 0.68825 ;v acc: 0.55\n",
      "Epoch 2 - Kfold:0 ;t loss: 0.68814 ;t acc: 0.53 ;v loss: 0.68616 ;v acc: 0.55\n",
      "Epoch 3 - Kfold:0 ;t loss: 0.68527 ;t acc: 0.55 ;v loss: 0.68405 ;v acc: 0.55\n",
      "Epoch 4 - Kfold:0 ;t loss: 0.68247 ;t acc: 0.56 ;v loss: 0.68217 ;v acc: 0.57\n",
      "Epoch 5 - Kfold:0 ;t loss: 0.67773 ;t acc: 0.57 ;v loss: 0.68012 ;v acc: 0.59\n",
      "Epoch 6 - Kfold:0 ;t loss: 0.67379 ;t acc: 0.58 ;v loss: 0.67867 ;v acc: 0.59\n",
      "Epoch 7 - Kfold:0 ;t loss: 0.66865 ;t acc: 0.60 ;v loss: 0.67526 ;v acc: 0.60\n",
      "Epoch 8 - Kfold:0 ;t loss: 0.66102 ;t acc: 0.61 ;v loss: 0.67384 ;v acc: 0.58\n",
      "Epoch 9 - Kfold:0 ;t loss: 0.65064 ;t acc: 0.63 ;v loss: 0.67109 ;v acc: 0.59\n",
      "Epoch 10 - Kfold:0 ;t loss: 0.64009 ;t acc: 0.64 ;v loss: 0.67039 ;v acc: 0.60\n",
      "Epoch 11 - Kfold:0 ;t loss: 0.63037 ;t acc: 0.64 ;v loss: 0.67199 ;v acc: 0.60\n",
      "Epoch 12 - Kfold:0 ;t loss: 0.62137 ;t acc: 0.65 ;v loss: 0.67333 ;v acc: 0.58\n",
      "Epoch 13 - Kfold:0 ;t loss: 0.61235 ;t acc: 0.66 ;v loss: 0.67423 ;v acc: 0.60\n",
      "Epoch 14 - Kfold:0 ;t loss: 0.60041 ;t acc: 0.67 ;v loss: 0.67564 ;v acc: 0.59\n",
      "Epoch 15 - Kfold:0 ;t loss: 0.59210 ;t acc: 0.67 ;v loss: 0.67842 ;v acc: 0.59\n",
      "Epoch 16 - Kfold:0 ;t loss: 0.58585 ;t acc: 0.69 ;v loss: 0.68018 ;v acc: 0.60\n",
      "Epoch 17 - Kfold:0 ;t loss: 0.57815 ;t acc: 0.68 ;v loss: 0.68353 ;v acc: 0.58\n",
      "Epoch 18 - Kfold:0 ;t loss: 0.57135 ;t acc: 0.70 ;v loss: 0.68538 ;v acc: 0.59\n",
      "Epoch 19 - Kfold:0 ;t loss: 0.56632 ;t acc: 0.70 ;v loss: 0.68662 ;v acc: 0.59\n",
      "Epoch 20 - Kfold:0 ;t loss: 0.55930 ;t acc: 0.71 ;v loss: 0.68955 ;v acc: 0.60\n",
      "Epoch 21 - Kfold:0 ;t loss: 0.54879 ;t acc: 0.72 ;v loss: 0.69338 ;v acc: 0.59\n",
      "Epoch 22 - Kfold:0 ;t loss: 0.54881 ;t acc: 0.72 ;v loss: 0.69638 ;v acc: 0.60\n",
      "Epoch 23 - Kfold:0 ;t loss: 0.53920 ;t acc: 0.72 ;v loss: 0.70020 ;v acc: 0.60\n",
      "Epoch 24 - Kfold:0 ;t loss: 0.53651 ;t acc: 0.74 ;v loss: 0.70498 ;v acc: 0.60\n",
      "Epoch 25 - Kfold:0 ;t loss: 0.52883 ;t acc: 0.73 ;v loss: 0.70870 ;v acc: 0.60\n",
      "Epoch 26 - Kfold:0 ;t loss: 0.52483 ;t acc: 0.74 ;v loss: 0.71086 ;v acc: 0.60\n",
      "Epoch 27 - Kfold:0 ;t loss: 0.51984 ;t acc: 0.74 ;v loss: 0.71522 ;v acc: 0.59\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "\n",
    "model = Model(train_dataset[0].x.shape[1])     \n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model parameter count: {pytorch_total_params}')\n",
    "\n",
    "model = model.to(device)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=.1, rho=0.9, eps=1e-06, weight_decay=1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=1e-1, weight_decay=1e-3)\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr=1e-4, weight_decay=1e-2)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-3, lr_decay=1e-4, weight_decay=1e-2)\n",
    "\n",
    "# Instantiate optimizer\n",
    "# scheduler = StepLR(optimizer, step_size=20, gamma=0.7)\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = torch.nn.SmoothL1Loss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "def train(loader, target = 0):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    right = 0\n",
    "    tot = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        y = (batch.y[:,target] > 5).float()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out,y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        right += torch.eq(out > .5, y > .5).sum().item()\n",
    "        tot += y.shape[0]\n",
    "    return np.array(losses).mean(), right/tot\n",
    "\n",
    "def test(loader,verbose=False, target = 0):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    right = 0\n",
    "    tot = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        y = (batch.y[:,target] > 5).float()\n",
    "        out = model(batch)\n",
    "        if verbose:\n",
    "            print(out,y)\n",
    "        loss = criterion(out,y)\n",
    "        losses.append(loss.item())\n",
    "        right += torch.eq(out > .5, y > .5).sum().item()\n",
    "        tot += y.shape[0]\n",
    "    return np.array(losses).mean(), right/tot\n",
    "\n",
    "best_val_loss = np.inf\n",
    "esp = 0\n",
    "MAX_ESP = 20\n",
    "\n",
    "BS = 1\n",
    "\n",
    "k_folds = 5\n",
    "k_fold_size = len(train_dataset)/k_folds\n",
    "current_fold = 0 # Ranges from 0 to k_folds-1\n",
    "\n",
    "target = 0 # Valence\n",
    "for epoch in range(1, 10000):    \n",
    "    # KFOLD train/val split     \n",
    "#     if epoch %10 == 0:\n",
    "#         current_fold = current_fold+1 if current_fold < k_folds-1 else 0\n",
    "    from_idx, to_idx = int(k_fold_size*current_fold), int(k_fold_size*(current_fold+1))\n",
    "    kf_val_data = train_dataset[from_idx:to_idx]\n",
    "    a = train_dataset[:from_idx]\n",
    "    b = train_dataset[to_idx:]\n",
    "    kf_train_data = a + b\n",
    "    train_loader = DataLoader(kf_train_data, batch_size=BS, shuffle=False)\n",
    "    val_loader = DataLoader(kf_val_data, batch_size=BS)\n",
    "        \n",
    "    # Training and validation\n",
    "    train_loss, train_acc = train(train_loader, target = target)\n",
    "    val_loss, val_acc = test(val_loader , target = target)\n",
    "    print(f'Epoch {epoch} - Kfold:{current_fold} ;t loss: {train_loss:.5f} ;t acc: {train_acc:.2f} ;v loss: {val_loss:.5f} ;v acc: {val_acc:.2f}')\n",
    "\n",
    "    # Early stopping and checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        esp = 0\n",
    "        torch.save(model.state_dict(),'./best_params') \n",
    "    else:\n",
    "        esp += 1\n",
    "        if esp >= MAX_ESP:\n",
    "            break\n",
    "            \n",
    "    if epoch % 50 == 0:\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "        loss, acc = test(test_loader, True)\n",
    "        print(f'Test loss: {loss} ; Test acc: {acc}')\n",
    "        \n",
    "#     scheduler.step()\n",
    "\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6555795839903029 ; Train acc: 0.6431818181818182\n",
      "Val loss: 0.6812206940217451 ; Val acc: 0.5681818181818182\n",
      "Test loss: 0.6765057153171963 ; Test acc: 0.5611111111111111\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./best_params'))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "loss, acc = test(train_loader, False)\n",
    "print(f'Train loss: {loss} ; Train acc: {acc}')\n",
    "loss, acc = test(val_loader, False)\n",
    "\n",
    "print(f'Val loss: {loss} ; Val acc: {acc}')\n",
    "loss, acc = test(test_loader, False)\n",
    "print(f'Test loss: {loss} ; Test acc: {acc}')\n",
    "\n",
    "# TODO: scheduler(?) Loss/acc records"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
