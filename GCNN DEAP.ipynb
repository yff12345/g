{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "from einops import reduce, rearrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data, DataLoader\n",
    "from Electrodes import Electrodes\n",
    "from tqdm import tqdm\n",
    "class DEAPDatasetEEGFeatures(InMemoryDataset):\n",
    "    \n",
    "  def __init__(self, root, raw_dir,processed_dir, transform=None, pre_transform=None,include_edge_attr = False, undirected_graphs = True, add_global_connections=True, participant_from=1, participant_to=32,window_size=128, n_videos=40):\n",
    "      self._raw_dir = raw_dir\n",
    "      self._processed_dir = processed_dir\n",
    "      self.participant_from = participant_from\n",
    "      self.participant_to = participant_to\n",
    "      self.n_videos = n_videos\n",
    "      self.window_size = window_size\n",
    "      # Whether or not to include edge_attr in the dataset\n",
    "      self.include_edge_attr = include_edge_attr\n",
    "      # If true there will be 1024 links as opposed to 528\n",
    "      self.undirected_graphs = undirected_graphs\n",
    "      # Instantiate class to handle electrode positions\n",
    "      print('Using global connections' if add_global_connections else 'Not using global connections')\n",
    "      self.electrodes = Electrodes(add_global_connections, expand_3d = False)\n",
    "      super(DEAPDatasetEEGFeatures, self).__init__(root, transform, pre_transform)\n",
    "      self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "      \n",
    "\n",
    "  @property\n",
    "  def raw_dir(self):\n",
    "      return f'{self.root}/{self._raw_dir}'\n",
    "\n",
    "  @property\n",
    "  def processed_dir(self):\n",
    "      return f'{self.root}/{self._processed_dir}'\n",
    "\n",
    "  @property\n",
    "  def raw_file_names(self):\n",
    "      raw_names = [f for f in os.listdir(self.raw_dir)]\n",
    "      raw_names.sort()\n",
    "      return raw_names\n",
    "\n",
    "  @property\n",
    "  def processed_file_names(self):\n",
    "      if not os.path.exists(self.processed_dir):\n",
    "        os.makedirs(self.processed_dir)\n",
    "      file_name = f'{self.participant_from}-{self.participant_to}' if self.participant_from is not self.participant_to else f'{self.participant_from}'\n",
    "      return [f'deap_processed_graph.{file_name}.dataset']\n",
    "\n",
    "  def process(self):\n",
    "        # Number of nodes per graph\n",
    "        n_nodes = len(self.electrodes.positions_3d)\n",
    "\n",
    "        if self.undirected_graphs:\n",
    "            source_nodes, target_nodes = np.repeat(np.arange(0,n_nodes),n_nodes), np.tile(np.arange(0,n_nodes),n_nodes)\n",
    "        else:\n",
    "            source_nodes, target_nodes = np.tril_indices(n_nodes,n_nodes)\n",
    "        \n",
    "        edge_attr = self.electrodes.adjacency_matrix[source_nodes,target_nodes]\n",
    "        \n",
    "        # Remove zero weight links\n",
    "        mask = np.ma.masked_not_equal(edge_attr, 0).mask\n",
    "        edge_attr,source_nodes,target_nodes = edge_attr[mask], source_nodes[mask], target_nodes[mask]\n",
    "\n",
    "        edge_attr, edge_index = torch.FloatTensor(edge_attr), torch.tensor([source_nodes,target_nodes], dtype=torch.long)\n",
    "        \n",
    "        # Expand edge_index and edge_attr to match windows\n",
    "        e_edge_index = edge_index.clone()\n",
    "        e_edge_attr = edge_attr.clone()\n",
    "        for i in range(128*60//self.window_size-1):\n",
    "            a = edge_index + e_edge_index.max() + 1\n",
    "            e_edge_index = torch.cat([e_edge_index,a],dim=1)\n",
    "            e_edge_attr = torch.cat([e_edge_attr,edge_attr],dim=0)\n",
    "\n",
    "        # List of graphs that will be written to file\n",
    "        data_list = []\n",
    "        pbar = tqdm(range(self.participant_from,self.participant_to+1))\n",
    "        for participant_id in pbar:\n",
    "            raw_name = [e for e in self.raw_file_names if str(participant_id).zfill(2) in e][0]\n",
    "            pbar.set_description(raw_name)\n",
    "            # Load raw file as np array\n",
    "            participant_data = scipy.io.loadmat(f'{self.raw_dir}/{raw_name}')\n",
    "            signal_data = torch.FloatTensor(participant_data['data'][:,:32,128*3:])\n",
    "            processed = []\n",
    "            for i, video in enumerate(signal_data[:self.n_videos,:,:]):\n",
    "                video = video.reshape(-1,128)\n",
    "                # Power spectral density for each channel\n",
    "                psd = scipy.signal.periodogram(video)[1]\n",
    "                # Should we add MinMax/Z scaler?\n",
    "                data = Data(x=torch.FloatTensor(psd),edge_attr=e_edge_attr,edge_index=e_edge_index, y=torch.FloatTensor([participant_data['labels'][i]])) if self.include_edge_attr else Data(x=torch.FloatTensor(psd), edge_index=e_edge_index, y=torch.FloatTensor([participant_data['labels'][i]]))\n",
    "                data_list.append(data) \n",
    "               \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s01.mat:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global connections\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s32.mat: 100%|██████████| 32/32 [00:19<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 11640], x=[1920, 65], y=[1, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants used to define data paths\n",
    "ROOT_DIR = './'\n",
    "RAW_DIR = 'data/matlabPREPROCESSED'\n",
    "PROCESSED_DIR = 'data/graphProcessedData'\n",
    "\n",
    "dataset = DEAPDatasetEEGFeatures(root= ROOT_DIR, raw_dir= RAW_DIR, processed_dir= PROCESSED_DIR)\n",
    "# Subject-independent classification\n",
    "dataset = dataset.shuffle()\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DEAPDatasetEEGFeatures(896),\n",
       " DEAPDatasetEEGFeatures(192),\n",
       " DEAPDatasetEEGFeatures(192))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 70% used for training, 15% validation and 15% testing\n",
    "splt_idx = (int(0.7*len(dataset)),int(0.85*len(dataset)))\n",
    "\n",
    "train_dataset = dataset[:splt_idx[0]]\n",
    "val_dataset = dataset[splt_idx[0]:splt_idx[1]]\n",
    "test_dataset = dataset[splt_idx[1]:]\n",
    "\n",
    "train_dataset,val_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Model, self).__init__()\n",
    "        self.gconv1 = GCNConv(in_channels, 256, aggr='add')\n",
    "        self.gconv2 = GCNConv(256, 128, aggr='add')\n",
    "        self.gconv3 = GCNConv(128, 1, aggr='add')\n",
    "        self.gconv4 = GCNConv(8, 1, aggr='add')\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(60, 8, 1, stride=1)\n",
    "        \n",
    "#         .to(device)\n",
    "        self.lin1 = nn.Linear(256,32)\n",
    "        self.lin2 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        bs = len(torch.unique(batch.batch))\n",
    "        x, edge_index = batch.x, batch.edge_index\n",
    "        \n",
    "#         print(x)\n",
    "        \n",
    "        x = self.gconv1(x, edge_index)\n",
    "#         print(x)\n",
    "        x = torch.tanh(x)\n",
    "        if x[0][0].isnan():\n",
    "            raise 'err'\n",
    "        x = self.gconv2(x, edge_index)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.gconv3(x, edge_index)\n",
    "        x = torch.tanh(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "#         x = self.gconv4(x, edge_index)\n",
    "#         x = torch.tanh(x)\n",
    "#         print(x)\n",
    "        x = x.reshape(bs,-1,32)\n",
    "#         x.relu()\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.reshape(bs,-1)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.lin1(x)\n",
    "        x.sigmoid()\n",
    "        x = self.lin2(x)\n",
    "#         print(x)\n",
    "#         raise 'err'\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter count: 58675\n",
      "Epoch 1 ;t loss: 8.88811 ;t acc: 0.49 ;v loss: 4.20414 ;v acc: 0.40\n",
      "Epoch 2 ;t loss: 4.82150 ;t acc: 0.53 ;v loss: 4.05339 ;v acc: 0.60\n",
      "Epoch 3 ;t loss: 4.83002 ;t acc: 0.53 ;v loss: 4.16717 ;v acc: 0.40\n",
      "Epoch 4 ;t loss: 4.86645 ;t acc: 0.51 ;v loss: 4.25214 ;v acc: 0.40\n",
      "Epoch 5 ;t loss: 4.88422 ;t acc: 0.50 ;v loss: 4.30437 ;v acc: 0.40\n",
      "Epoch 6 ;t loss: 4.89220 ;t acc: 0.50 ;v loss: 4.33029 ;v acc: 0.40\n",
      "Epoch 7 ;t loss: 4.89549 ;t acc: 0.50 ;v loss: 4.33893 ;v acc: 0.40\n",
      "Epoch 8 ;t loss: 4.89643 ;t acc: 0.50 ;v loss: 4.33632 ;v acc: 0.40\n",
      "Epoch 9 ;t loss: 4.89592 ;t acc: 0.50 ;v loss: 4.32627 ;v acc: 0.40\n",
      "Epoch 10 ;t loss: 4.89453 ;t acc: 0.50 ;v loss: 4.31151 ;v acc: 0.40\n",
      "Epoch 11 ;t loss: 4.89262 ;t acc: 0.50 ;v loss: 4.29276 ;v acc: 0.40\n",
      "Epoch 12 ;t loss: 4.88954 ;t acc: 0.50 ;v loss: 4.27284 ;v acc: 0.40\n",
      "Epoch 13 ;t loss: 4.88601 ;t acc: 0.50 ;v loss: 4.25128 ;v acc: 0.39\n",
      "Epoch 14 ;t loss: 4.88216 ;t acc: 0.50 ;v loss: 4.23051 ;v acc: 0.40\n",
      "Epoch 15 ;t loss: 4.87776 ;t acc: 0.50 ;v loss: 4.21071 ;v acc: 0.40\n",
      "Epoch 16 ;t loss: 4.87315 ;t acc: 0.52 ;v loss: 4.19100 ;v acc: 0.40\n",
      "Epoch 17 ;t loss: 4.86830 ;t acc: 0.51 ;v loss: 4.17211 ;v acc: 0.40\n",
      "Epoch 18 ;t loss: 4.86335 ;t acc: 0.51 ;v loss: 4.15467 ;v acc: 0.40\n",
      "Epoch 19 ;t loss: 4.85841 ;t acc: 0.51 ;v loss: 4.13865 ;v acc: 0.40\n",
      "Epoch 20 ;t loss: 4.85360 ;t acc: 0.51 ;v loss: 4.12447 ;v acc: 0.61\n",
      "Epoch 21 ;t loss: 4.84877 ;t acc: 0.51 ;v loss: 4.11168 ;v acc: 0.61\n",
      "Epoch 22 ;t loss: 4.84408 ;t acc: 0.51 ;v loss: 4.10036 ;v acc: 0.61\n",
      "Epoch 23 ;t loss: 4.83963 ;t acc: 0.52 ;v loss: 4.09015 ;v acc: 0.61\n",
      "Epoch 24 ;t loss: 4.83537 ;t acc: 0.52 ;v loss: 4.08132 ;v acc: 0.61\n",
      "Epoch 25 ;t loss: 4.83142 ;t acc: 0.53 ;v loss: 4.07474 ;v acc: 0.60\n",
      "Epoch 26 ;t loss: 4.82807 ;t acc: 0.52 ;v loss: 4.06829 ;v acc: 0.60\n",
      "Epoch 27 ;t loss: 4.82480 ;t acc: 0.52 ;v loss: 4.06169 ;v acc: 0.60\n",
      "Epoch 28 ;t loss: 4.82122 ;t acc: 0.52 ;v loss: 4.05566 ;v acc: 0.60\n",
      "Epoch 29 ;t loss: 4.81783 ;t acc: 0.52 ;v loss: 4.05037 ;v acc: 0.60\n",
      "Epoch 30 ;t loss: 4.81466 ;t acc: 0.52 ;v loss: 4.04569 ;v acc: 0.60\n",
      "Epoch 31 ;t loss: 4.81170 ;t acc: 0.52 ;v loss: 4.04161 ;v acc: 0.60\n",
      "Epoch 32 ;t loss: 4.80888 ;t acc: 0.52 ;v loss: 4.03873 ;v acc: 0.60\n",
      "Epoch 33 ;t loss: 4.80627 ;t acc: 0.52 ;v loss: 4.03418 ;v acc: 0.60\n",
      "Epoch 34 ;t loss: 4.80382 ;t acc: 0.53 ;v loss: 4.03155 ;v acc: 0.60\n",
      "Epoch 35 ;t loss: 4.80162 ;t acc: 0.53 ;v loss: 4.02895 ;v acc: 0.60\n",
      "Epoch 36 ;t loss: 4.79943 ;t acc: 0.53 ;v loss: 4.02730 ;v acc: 0.60\n",
      "Epoch 37 ;t loss: 4.79752 ;t acc: 0.53 ;v loss: 4.02604 ;v acc: 0.60\n",
      "Epoch 38 ;t loss: 4.79553 ;t acc: 0.53 ;v loss: 4.02380 ;v acc: 0.60\n",
      "Epoch 39 ;t loss: 4.79456 ;t acc: 0.53 ;v loss: 4.02055 ;v acc: 0.60\n",
      "Epoch 40 ;t loss: 4.79214 ;t acc: 0.54 ;v loss: 4.01900 ;v acc: 0.60\n",
      "Epoch 41 ;t loss: 4.79048 ;t acc: 0.54 ;v loss: 4.01750 ;v acc: 0.60\n",
      "Epoch 42 ;t loss: 4.78897 ;t acc: 0.54 ;v loss: 4.01615 ;v acc: 0.60\n",
      "Epoch 43 ;t loss: 4.78754 ;t acc: 0.54 ;v loss: 4.01492 ;v acc: 0.60\n",
      "Epoch 44 ;t loss: 4.78620 ;t acc: 0.54 ;v loss: 4.01380 ;v acc: 0.60\n",
      "Epoch 45 ;t loss: 4.78493 ;t acc: 0.54 ;v loss: 4.01280 ;v acc: 0.60\n",
      "Epoch 46 ;t loss: 4.78372 ;t acc: 0.54 ;v loss: 4.01194 ;v acc: 0.60\n",
      "Epoch 47 ;t loss: 4.78258 ;t acc: 0.54 ;v loss: 4.01154 ;v acc: 0.60\n",
      "Epoch 48 ;t loss: 4.83143 ;t acc: 0.53 ;v loss: 4.00922 ;v acc: 0.60\n",
      "Epoch 49 ;t loss: 4.77988 ;t acc: 0.54 ;v loss: 4.01628 ;v acc: 0.60\n",
      "Epoch 50 ;t loss: 4.78179 ;t acc: 0.54 ;v loss: 4.01036 ;v acc: 0.60\n",
      "Epoch 51 ;t loss: 4.77934 ;t acc: 0.54 ;v loss: 4.00870 ;v acc: 0.60\n",
      "Epoch 52 ;t loss: 4.77799 ;t acc: 0.54 ;v loss: 4.00812 ;v acc: 0.60\n",
      "Epoch 53 ;t loss: 4.77712 ;t acc: 0.54 ;v loss: 4.00762 ;v acc: 0.60\n",
      "Epoch 54 ;t loss: 4.77634 ;t acc: 0.54 ;v loss: 4.00717 ;v acc: 0.60\n",
      "Epoch 55 ;t loss: 4.77561 ;t acc: 0.54 ;v loss: 4.00676 ;v acc: 0.60\n",
      "Epoch 56 ;t loss: 4.77491 ;t acc: 0.54 ;v loss: 4.00638 ;v acc: 0.60\n",
      "Epoch 57 ;t loss: 4.77424 ;t acc: 0.54 ;v loss: 4.00603 ;v acc: 0.60\n",
      "Epoch 58 ;t loss: 4.77360 ;t acc: 0.54 ;v loss: 4.00570 ;v acc: 0.60\n",
      "Epoch 59 ;t loss: 4.77298 ;t acc: 0.54 ;v loss: 4.00542 ;v acc: 0.60\n",
      "Epoch 60 ;t loss: 4.77240 ;t acc: 0.54 ;v loss: 4.00519 ;v acc: 0.60\n",
      "Epoch 61 ;t loss: 4.77185 ;t acc: 0.54 ;v loss: 4.00518 ;v acc: 0.60\n",
      "Epoch 62 ;t loss: 4.77142 ;t acc: 0.54 ;v loss: 4.00573 ;v acc: 0.60\n",
      "Epoch 63 ;t loss: 4.77122 ;t acc: 0.54 ;v loss: 4.00598 ;v acc: 0.60\n",
      "Epoch 64 ;t loss: 4.77095 ;t acc: 0.54 ;v loss: 4.00437 ;v acc: 0.60\n",
      "Epoch 65 ;t loss: 4.76983 ;t acc: 0.54 ;v loss: 4.00393 ;v acc: 0.60\n",
      "Epoch 66 ;t loss: 4.76913 ;t acc: 0.54 ;v loss: 4.00373 ;v acc: 0.60\n",
      "Epoch 67 ;t loss: 4.76860 ;t acc: 0.54 ;v loss: 4.00358 ;v acc: 0.60\n",
      "Epoch 68 ;t loss: 4.76813 ;t acc: 0.54 ;v loss: 4.00365 ;v acc: 0.60\n",
      "Epoch 69 ;t loss: 4.76782 ;t acc: 0.54 ;v loss: 4.00479 ;v acc: 0.60\n",
      "Epoch 70 ;t loss: 4.76790 ;t acc: 0.54 ;v loss: 4.00505 ;v acc: 0.60\n",
      "Epoch 71 ;t loss: 4.76781 ;t acc: 0.54 ;v loss: 4.00276 ;v acc: 0.60\n",
      "Epoch 72 ;t loss: 4.76626 ;t acc: 0.54 ;v loss: 4.00289 ;v acc: 0.60\n",
      "Epoch 73 ;t loss: 4.76585 ;t acc: 0.54 ;v loss: 4.00308 ;v acc: 0.60\n",
      "Epoch 74 ;t loss: 4.76559 ;t acc: 0.54 ;v loss: 4.00350 ;v acc: 0.60\n",
      "Epoch 75 ;t loss: 4.76547 ;t acc: 0.54 ;v loss: 4.00299 ;v acc: 0.60\n",
      "Epoch 76 ;t loss: 4.76494 ;t acc: 0.54 ;v loss: 4.00339 ;v acc: 0.60\n",
      "Epoch 77 ;t loss: 4.76472 ;t acc: 0.54 ;v loss: 4.00510 ;v acc: 0.60\n",
      "Epoch 78 ;t loss: 4.76526 ;t acc: 0.54 ;v loss: 4.00181 ;v acc: 0.60\n",
      "Epoch 79 ;t loss: 4.76318 ;t acc: 0.54 ;v loss: 4.00214 ;v acc: 0.60\n",
      "Epoch 80 ;t loss: 4.76283 ;t acc: 0.54 ;v loss: 4.00210 ;v acc: 0.60\n",
      "Epoch 81 ;t loss: 4.76244 ;t acc: 0.54 ;v loss: 4.00211 ;v acc: 0.60\n",
      "Epoch 82 ;t loss: 4.76212 ;t acc: 0.54 ;v loss: 4.00243 ;v acc: 0.60\n",
      "Epoch 83 ;t loss: 4.76201 ;t acc: 0.54 ;v loss: 4.00357 ;v acc: 0.60\n",
      "Epoch 84 ;t loss: 4.76236 ;t acc: 0.54 ;v loss: 4.00245 ;v acc: 0.60\n",
      "Epoch 85 ;t loss: 4.76152 ;t acc: 0.54 ;v loss: 4.00225 ;v acc: 0.60\n",
      "Epoch 86 ;t loss: 4.76094 ;t acc: 0.54 ;v loss: 4.00190 ;v acc: 0.60\n",
      "Epoch 87 ;t loss: 4.76029 ;t acc: 0.54 ;v loss: 4.00186 ;v acc: 0.60\n",
      "Epoch 88 ;t loss: 4.75982 ;t acc: 0.54 ;v loss: 4.00187 ;v acc: 0.60\n",
      "Epoch 89 ;t loss: 4.75943 ;t acc: 0.54 ;v loss: 4.00188 ;v acc: 0.60\n",
      "Epoch 90 ;t loss: 4.75907 ;t acc: 0.54 ;v loss: 4.00192 ;v acc: 0.60\n",
      "Epoch 91 ;t loss: 4.75876 ;t acc: 0.54 ;v loss: 4.00223 ;v acc: 0.60\n",
      "Epoch 92 ;t loss: 4.75869 ;t acc: 0.54 ;v loss: 4.00387 ;v acc: 0.60\n",
      "Epoch 93 ;t loss: 4.75941 ;t acc: 0.54 ;v loss: 4.00198 ;v acc: 0.60\n",
      "Epoch 94 ;t loss: 4.75810 ;t acc: 0.54 ;v loss: 4.00286 ;v acc: 0.60\n",
      "Epoch 95 ;t loss: 4.75818 ;t acc: 0.54 ;v loss: 4.00248 ;v acc: 0.60\n",
      "Epoch 96 ;t loss: 4.75771 ;t acc: 0.54 ;v loss: 4.00193 ;v acc: 0.60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-73e42b1800c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mMAX_ESP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#     if val_loss <= best_val_loss:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-73e42b1800c0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mright\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(dataset[0].x[1].shape[0])     \n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model parameter count: {pytorch_total_params}')\n",
    "\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=.1, rho=0.9, eps=1e-06, weight_decay=1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=1e-1, weight_decay=1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    losses = []\n",
    "    right = 0\n",
    "    tot = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        y = batch.y[:,0] # Valence\n",
    "        out = model(batch)\n",
    "        loss = criterion(out,y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        right += torch.eq(out > 5, y > 5).sum().item()\n",
    "        tot += y.shape[0]\n",
    "    return np.array(losses).mean(), right/tot\n",
    "\n",
    "def test(loader,verbose=False):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    right = 0\n",
    "    tot = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        y = batch.y[:,0] # Valence\n",
    "        out = model(batch)\n",
    "        loss = criterion(out,y)\n",
    "        losses.append(loss.item())\n",
    "        right += torch.eq(out > 5, y > 5).sum().item()\n",
    "        tot += y.shape[0]\n",
    "    return np.array(losses).mean(), right/tot\n",
    "\n",
    "best_val_loss = np.inf\n",
    "esp = 0\n",
    "MAX_ESP = 50\n",
    "for epoch in range(1, 1000):\n",
    "    train_loss, train_acc = train()\n",
    "    val_loss, val_acc = test(val_loader)\n",
    "#     if val_loss <= best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         esp = 0\n",
    "#     else:\n",
    "#         esp += 1\n",
    "#         if esp >= MAX_ESP:\n",
    "#             break\n",
    "#     if epoch%5 == 0:\n",
    "    print(f'Epoch {epoch} ;t loss: {train_loss:.5f} ;t acc: {train_acc:.2f} ;v loss: {val_loss:.5f} ;v acc: {val_acc:.2f}')\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.422489643096924 ; Test acc: 0.578125\n"
     ]
    }
   ],
   "source": [
    "loss, acc = test(test_loader)\n",
    "print(f'Test loss: {loss} ; Test acc: {acc}')\n",
    "\n",
    "# TODO: esp, kfold val , scheduler(?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
