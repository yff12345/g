{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "from einops import reduce, rearrange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from npeet import entropy_estimators as ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Video with shape (32,7680)\n",
    "# Output: Graph node features with shape (60*32,5) -> 60 graphs with 32 electrodes each with 5 features each\n",
    "def process_video_de(video):\n",
    "    # Delta, Theta, Alpha, Beta, Gamma\n",
    "    bands = [(0,3),(4,7),(8,13),(14,30),(31,50)]\n",
    "    # Split into windows\n",
    "    video = video.reshape(-1,32,128)\n",
    "    node_features = []\n",
    "    # For each window with shape (32,128) \n",
    "    for window in video:\n",
    "        graph_features = []\n",
    "        # Get frequency bands and calculate DE for each band -> (32,5)\n",
    "        for channel in window:\n",
    "            # Transform to frequency domain\n",
    "            fft_vals = np.fft.rfft(channel)\n",
    "            fft_vals = np.abs(fft_vals)\n",
    "            # Get values for different bands and compute DE\n",
    "            de_features = [ee.entropy(fft_vals[f:t].reshape(-1,1), k=2) for f,t in bands]\n",
    "            graph_features.append(de_features)\n",
    "            \n",
    "        node_features.append(graph_features)\n",
    "    node_features = torch.FloatTensor(node_features).reshape(-1,5)\n",
    "    return node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data, DataLoader\n",
    "from Electrodes import Electrodes\n",
    "from tqdm import tqdm\n",
    "class DEAPDatasetEEGFeatures(InMemoryDataset):\n",
    "    \n",
    "  def __init__(self, root, raw_dir,processed_dir, transform=None, pre_transform=None,include_edge_attr = False, undirected_graphs = True, add_global_connections=True, participant_from=1, participant_to=32,window_size=128, n_videos=40):\n",
    "      self._raw_dir = raw_dir\n",
    "      self._processed_dir = processed_dir\n",
    "      self.participant_from = participant_from\n",
    "      self.participant_to = participant_to\n",
    "      self.n_videos = n_videos\n",
    "      self.window_size = window_size\n",
    "      # Whether or not to include edge_attr in the dataset\n",
    "      self.include_edge_attr = include_edge_attr\n",
    "      # If true there will be 1024 links as opposed to 528\n",
    "      self.undirected_graphs = undirected_graphs\n",
    "      # Instantiate class to handle electrode positions\n",
    "      print('Using global connections' if add_global_connections else 'Not using global connections')\n",
    "      self.electrodes = Electrodes(add_global_connections, expand_3d = False)\n",
    "      super(DEAPDatasetEEGFeatures, self).__init__(root, transform, pre_transform)\n",
    "      self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "      \n",
    "\n",
    "  @property\n",
    "  def raw_dir(self):\n",
    "      return f'{self.root}/{self._raw_dir}'\n",
    "\n",
    "  @property\n",
    "  def processed_dir(self):\n",
    "      return f'{self.root}/{self._processed_dir}'\n",
    "\n",
    "  @property\n",
    "  def raw_file_names(self):\n",
    "      raw_names = [f for f in os.listdir(self.raw_dir)]\n",
    "      raw_names.sort()\n",
    "      return raw_names\n",
    "\n",
    "  @property\n",
    "  def processed_file_names(self):\n",
    "      if not os.path.exists(self.processed_dir):\n",
    "        os.makedirs(self.processed_dir)\n",
    "      file_name = f'{self.participant_from}-{self.participant_to}' if self.participant_from is not self.participant_to else f'{self.participant_from}'\n",
    "      return [f'deap_processed_graph.{file_name}.dataset']\n",
    "\n",
    "  def process(self):\n",
    "        # Number of nodes per graph\n",
    "        n_nodes = len(self.electrodes.positions_3d)\n",
    "\n",
    "        if self.undirected_graphs:\n",
    "            source_nodes, target_nodes = np.repeat(np.arange(0,n_nodes),n_nodes), np.tile(np.arange(0,n_nodes),n_nodes)\n",
    "        else:\n",
    "            source_nodes, target_nodes = np.tril_indices(n_nodes,n_nodes)\n",
    "        \n",
    "        edge_attr = self.electrodes.adjacency_matrix[source_nodes,target_nodes]\n",
    "        \n",
    "        # Remove zero weight links\n",
    "        mask = np.ma.masked_not_equal(edge_attr, 0).mask\n",
    "        edge_attr,source_nodes,target_nodes = edge_attr[mask], source_nodes[mask], target_nodes[mask]\n",
    "\n",
    "        edge_attr, edge_index = torch.FloatTensor(edge_attr), torch.tensor([source_nodes,target_nodes], dtype=torch.long)\n",
    "        \n",
    "        # Expand edge_index and edge_attr to match windows\n",
    "        e_edge_index = edge_index.clone()\n",
    "        e_edge_attr = edge_attr.clone()\n",
    "        for i in range(59):\n",
    "            a = edge_index + e_edge_index.max() + 1\n",
    "            e_edge_index = torch.cat([e_edge_index,a],dim=1)\n",
    "            e_edge_attr = torch.cat([e_edge_attr,edge_attr],dim=0)\n",
    "\n",
    "        print(e_edge_index)\n",
    "        # List of graphs that will be written to file\n",
    "        data_list = []\n",
    "        pbar = tqdm(range(self.participant_from,self.participant_to+1))\n",
    "        for participant_id in pbar:\n",
    "            raw_name = [e for e in self.raw_file_names if str(participant_id).zfill(2) in e][0]\n",
    "            pbar.set_description(raw_name)\n",
    "            # Load raw file as np array\n",
    "            participant_data = scipy.io.loadmat(f'{self.raw_dir}/{raw_name}')\n",
    "            signal_data = torch.FloatTensor(participant_data['data'][:,:32,128*3:])\n",
    "            processed = []\n",
    "            for i, video in enumerate(signal_data[:self.n_videos,:,:]):\n",
    "                \n",
    "                # Differential entropy for each band\n",
    "                node_features = process_video_de(video)\n",
    "\n",
    "                # Power spectral density for each channel\n",
    "                # psd = scipy.signal.periodogram(video)[1]\n",
    "                # node_features = psd\n",
    "                \n",
    "                # Raw signals \n",
    "                # node_features = video\n",
    "                \n",
    "                # Should we add MinMax/Z scaler?\n",
    "                data = Data(x=torch.FloatTensor(node_features),edge_attr=e_edge_attr,edge_index=e_edge_index, y=torch.FloatTensor([participant_data['labels'][i]])) if self.include_edge_attr else Data(x=torch.FloatTensor(node_features), edge_index=e_edge_index, y=torch.FloatTensor([participant_data['labels'][i]]))\n",
    "                data_list.append(data) \n",
    "               \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global connections\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 11640], x=[1920, 5], y=[1, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants used to define data paths\n",
    "ROOT_DIR = './'\n",
    "RAW_DIR = 'data/matlabPREPROCESSED'\n",
    "PROCESSED_DIR = 'data/graphProcessedData'\n",
    "\n",
    "dataset = DEAPDatasetEEGFeatures(root= ROOT_DIR, raw_dir= RAW_DIR, processed_dir= PROCESSED_DIR)\n",
    "# Subject-independent classification\n",
    "# DEPENDING ON WHAT DATA IS USED THE NETWORK LEARNS BETTER OR WORSE.\n",
    "# SHOULD WE TRY TO HAVE A BALANCE TRAINING SET?\n",
    "dataset = dataset.shuffle()\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_channel(data):\n",
    "\n",
    "    data = data.reshape(-1,128)\n",
    "\n",
    "    # Differential entropy features\n",
    "    de_features = np.array([])\n",
    "    n = 128\n",
    "    for window in data:\n",
    "\n",
    "        fourier = np.fft.rfft(window)\n",
    "        real_absolute_fft = 2.0/n * np.abs(fourier[:n//2])\n",
    "        freq = np.fft.rfftfreq(n, d=1./128)\n",
    "\n",
    "        delta_mask = np.logical_and(freq > 0.5 ,freq < 4)[:64]\n",
    "        delta_values = real_absolute_fft[delta_mask]\n",
    "        delta_entropy = scipy.stats.entropy(delta_values)\n",
    "\n",
    "        theta_mask = np.logical_and(freq > 4 ,freq < 8)[:64]\n",
    "        theta_values = real_absolute_fft[theta_mask]\n",
    "        theta_entropy = scipy.stats.entropy(theta_values)\n",
    "\n",
    "        alpha_mask = np.logical_and(freq > 8 ,freq < 12)[:64]\n",
    "        alpha_values = real_absolute_fft[alpha_mask]\n",
    "        alpha_entropy = scipy.stats.entropy(alpha_values)\n",
    "\n",
    "        beta_mask = np.logical_and(freq > 12 ,freq < 30)[:64]\n",
    "        beta_values = real_absolute_fft[beta_mask]\n",
    "        beta_entropy = scipy.stats.entropy(beta_values)\n",
    "\n",
    "        gamma_mask = np.logical_and(freq > 30 ,freq < 45)[:64]\n",
    "        gamma_values = real_absolute_fft[gamma_mask]\n",
    "        gamma_entropy = scipy.stats.entropy(gamma_values)\n",
    "\n",
    "        window_features = np.array([delta_entropy, theta_entropy, alpha_entropy, beta_entropy, gamma_entropy])\n",
    "        window_features = window_features.reshape(1,-1)\n",
    "        de_features = np.concatenate([de_features, window_features]) if len(de_features) > 0 else window_features\n",
    "\n",
    "    return de_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DEAPDatasetEEGFeatures(1100), DEAPDatasetEEGFeatures(180))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 880 used for training, 220 validation and 180 testing\n",
    "splt_idx = 1100\n",
    "# splt_idx = 35\n",
    "\n",
    "# 85% used for train/val\n",
    "train_dataset = dataset[:splt_idx]\n",
    "test_dataset = dataset[splt_idx:]\n",
    "\n",
    "train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=32):\n",
    "        super(Model, self).__init__()\n",
    "        self.gconv1 = GCNConv(in_channels, hidden_channels, aggr='add')\n",
    "        self.gconv2 = GCNConv(hidden_channels, hidden_channels, aggr='add')\n",
    "#         self.gconv3 = GCNConv(64, 1, aggr='add')\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(5*60, hidden_channels, 1, stride=1)\n",
    "        \n",
    "        self.lin1 = nn.Linear(32*hidden_channels,32)\n",
    "        self.lin2 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        bs = len(torch.unique(batch.batch))\n",
    "        x, edge_index = batch.x, batch.edge_index\n",
    "#         print(x.shape)\n",
    "        x = x.reshape(-1,5)\n",
    "        \n",
    "        x = self.gconv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "#         print(x.shape)\n",
    "#         raise 'err'\n",
    "        x = self.gconv2(x, edge_index)\n",
    "        x = torch.tanh(x)\n",
    "#         x = self.gconv3(x, edge_index)\n",
    "#         x = torch.tanh(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.reshape(bs,-1,32)\n",
    "\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.reshape(bs,-1)\n",
    "        \n",
    "        x = self.lin1(x)\n",
    "        x.sigmoid()\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter count: 43713\n",
      "Epoch 1 - Kfold:0 ;t loss: 7.91549 ;t acc: 0.50 ;v loss: 7.77971 ;v acc: 0.46\n",
      "Epoch 2 - Kfold:0 ;t loss: 5.86289 ;t acc: 0.52 ;v loss: 7.39541 ;v acc: 0.46\n",
      "Epoch 3 - Kfold:0 ;t loss: 5.87334 ;t acc: 0.51 ;v loss: 8.05335 ;v acc: 0.46\n",
      "Epoch 4 - Kfold:0 ;t loss: 5.84175 ;t acc: 0.49 ;v loss: 7.29349 ;v acc: 0.46\n",
      "Epoch 5 - Kfold:0 ;t loss: 5.89952 ;t acc: 0.48 ;v loss: 8.15960 ;v acc: 0.46\n",
      "Epoch 6 - Kfold:0 ;t loss: 5.72797 ;t acc: 0.51 ;v loss: 8.03312 ;v acc: 0.46\n",
      "Epoch 7 - Kfold:0 ;t loss: 5.39130 ;t acc: 0.51 ;v loss: 7.47838 ;v acc: 0.46\n",
      "Epoch 8 - Kfold:0 ;t loss: 5.55067 ;t acc: 0.50 ;v loss: 7.40659 ;v acc: 0.46\n",
      "Epoch 9 - Kfold:0 ;t loss: 5.49199 ;t acc: 0.47 ;v loss: 7.55152 ;v acc: 0.46\n",
      "Epoch 10 - Kfold:0 ;t loss: 5.53471 ;t acc: 0.47 ;v loss: 7.76020 ;v acc: 0.46\n",
      "Epoch 11 - Kfold:0 ;t loss: 5.37827 ;t acc: 0.49 ;v loss: 7.65435 ;v acc: 0.46\n",
      "Epoch 12 - Kfold:0 ;t loss: 5.31531 ;t acc: 0.50 ;v loss: 8.01286 ;v acc: 0.46\n",
      "Epoch 13 - Kfold:0 ;t loss: 5.49592 ;t acc: 0.49 ;v loss: 7.47160 ;v acc: 0.46\n",
      "Epoch 14 - Kfold:0 ;t loss: 5.19951 ;t acc: 0.50 ;v loss: 7.43549 ;v acc: 0.46\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fd259ef43dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch} - Kfold:{current_fold} ;t loss: {train_loss:.5f} ;t acc: {train_acc:.2f} ;v loss: {val_loss:.5f} ;v acc: {val_acc:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-fd259ef43dc7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(loader, target)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mright\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adam does not support sparse gradients, please consider SparseAdam instead'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \"\"\"\n\u001b[1;32m    941\u001b[0m         \u001b[0mrelevant_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0;31m# TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "\n",
    "model = Model(5)     \n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model parameter count: {pytorch_total_params}')\n",
    "\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=.1, rho=0.9, eps=1e-06, weight_decay=1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=1e-1, weight_decay=1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "def train(loader, target = 0):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    right = 0\n",
    "    tot = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        y = batch.y[:,target] \n",
    "        out = model(batch)\n",
    "        loss = criterion(out,y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        right += torch.eq(out > 5, y > 5).sum().item()\n",
    "        tot += y.shape[0]\n",
    "    return np.array(losses).mean(), right/tot\n",
    "\n",
    "def test(loader,verbose=False, target = 0):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    right = 0\n",
    "    tot = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        y = batch.y[:,0] # Arousal\n",
    "        out = model(batch)\n",
    "        if verbose:\n",
    "            print(out,y)\n",
    "        loss = criterion(out,y)\n",
    "        losses.append(loss.item())\n",
    "        right += torch.eq(out > 5, y > 5).sum().item()\n",
    "        tot += y.shape[0]\n",
    "    return np.array(losses).mean(), right/tot\n",
    "\n",
    "best_val_loss = np.inf\n",
    "esp = 0\n",
    "MAX_ESP = 60\n",
    "\n",
    "BS = 16\n",
    "\n",
    "k_folds = 5\n",
    "k_fold_size = len(train_dataset)/k_folds\n",
    "current_fold = 0 # Ranges from 0 to k_folds-1\n",
    "\n",
    "target = 0 # Valence\n",
    "for epoch in range(1, 10000):    \n",
    "    # KFOLD train/val split     \n",
    "    if epoch %50 == 0:\n",
    "        current_fold = current_fold+1 if current_fold < k_folds-1 else 0\n",
    "    from_idx, to_idx = int(k_fold_size*current_fold), int(k_fold_size*(current_fold+1))\n",
    "    kf_val_data = train_dataset[from_idx:to_idx]\n",
    "    a = train_dataset[:from_idx]\n",
    "    b = train_dataset[to_idx:]\n",
    "    kf_train_data = a + b\n",
    "    train_loader = DataLoader(kf_train_data, batch_size=BS, shuffle=False)\n",
    "    val_loader = DataLoader(kf_val_data, batch_size=BS)\n",
    "        \n",
    "    # Training and validation\n",
    "    train_loss, train_acc = train(train_loader, target = target)\n",
    "    val_loss, val_acc = test(val_loader , target = target)\n",
    "    print(f'Epoch {epoch} - Kfold:{current_fold} ;t loss: {train_loss:.5f} ;t acc: {train_acc:.2f} ;v loss: {val_loss:.5f} ;v acc: {val_acc:.2f}')\n",
    "\n",
    "    # Early stopping and checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        esp = 0\n",
    "        torch.save(model.state_dict(),'./best_params') \n",
    "    else:\n",
    "        esp += 1\n",
    "        if esp >= MAX_ESP:\n",
    "            break\n",
    "\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.539971546693281 ; Train acc: 0.553409090909091\n",
      "Val loss: 4.501244800431388 ; Val acc: 0.5954545454545455\n",
      "Test loss: 4.429162561893463 ; Test acc: 0.55\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./best_params'))\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS)\n",
    "loss, acc = test(train_loader, False)\n",
    "print(f'Train loss: {loss} ; Train acc: {acc}')\n",
    "loss, acc = test(val_loader, False)\n",
    "print(f'Val loss: {loss} ; Val acc: {acc}')\n",
    "loss, acc = test(test_loader, False)\n",
    "print(f'Test loss: {loss} ; Test acc: {acc}')\n",
    "\n",
    "# TODO: scheduler(?) Loss/acc records"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
