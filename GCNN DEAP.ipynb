{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "from einops import reduce, rearrange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from npeet import entropy_estimators as ee\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import rfft, rfftfreq, ifft\n",
    "import scipy.signal\n",
    "from einops import rearrange\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_data = scipy.io.loadmat(f'data/matlabPREPROCESSED/s01.mat')\n",
    "signal_data = torch.FloatTensor(participant_data['data'][:,:32,128*3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Video with shape (32,7680)\n",
    "# Output: Graph node features with shape (59*32, 5) -> 59 graphs with 32 nodes each with 5 features each\n",
    "def process_video(video, feature='psd'):\n",
    "    assert feature in ['psd', 'de']\n",
    "    # Delta, Theta, Alpha, Beta, Gamma\n",
    "    bands = [(0,4),(4,8),(8,12),(12,30),(30,45)]\n",
    "    # Split into windows\n",
    "    samplingFrequency = 128\n",
    "    main_features = []\n",
    "    for channel in video:\n",
    "        # Transform to frequency domain\n",
    "        # Get real amplitudes of FFT (only in positive frequencies) ->rfft=real fast fourier transformation (on real inputs)\n",
    "        fft_vals = np.fft.rfft(channel)\n",
    "        # Get frequencies for amplitudes in Hz\n",
    "        fft_freq = np.fft.rfftfreq(len(channel), 1.0/samplingFrequency)\n",
    "        band_data = []\n",
    "        for f,t in bands:\n",
    "            mask = np.logical_or(fft_freq < f, fft_freq > t)\n",
    "            band = fft_vals.copy()\n",
    "            band[mask] = 0\n",
    "            band_data.append(band)\n",
    "        inverse = [np.fft.irfft(band) for band in band_data]\n",
    "        channel_features = []\n",
    "        for inv in inverse:\n",
    "            freq_band_features = []\n",
    "            idx = 0\n",
    "            while idx+256 <= len(inv):\n",
    "                if feature=='psd':\n",
    "                    a = scipy.signal.periodogram(inv[idx:idx+256])[1]\n",
    "                    freq_band_features.append(a.mean())\n",
    "                if feature=='de':\n",
    "                    a= ee.entropy(inv[idx:idx+256].reshape(-1,1), k=2)\n",
    "                    freq_band_features.append(a)\n",
    "                idx += 128\n",
    "            channel_features.append(freq_band_features)\n",
    "            \n",
    "        channel_features = np.array(channel_features).transpose(1,0)\n",
    "\n",
    "#         psds = (psds - psds.min()) / (psds.max() - psds.min())\n",
    "        channel_features = stats.zscore(channel_features)\n",
    "\n",
    "        main_features.append(channel_features)\n",
    "    main_features = torch.FloatTensor(main_features)\n",
    "    main_features = rearrange(main_features,'a b c -> (b a) c')\n",
    "    return main_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for video in signal_data[:10]:\n",
    "    process_video(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data, DataLoader\n",
    "from Electrodes import Electrodes\n",
    "from tqdm import tqdm\n",
    "class DEAPDatasetEEGFeatures(InMemoryDataset):\n",
    "    \n",
    "  def __init__(self, root, raw_dir,processed_dir,feature='psd', transform=None, pre_transform=None,include_edge_attr = False, undirected_graphs = True, add_global_connections=True, participant_from=1, participant_to=32,window_size=128, n_videos=40):\n",
    "      self._raw_dir = raw_dir\n",
    "      self._processed_dir = processed_dir\n",
    "      self.participant_from = participant_from\n",
    "      self.participant_to = participant_to\n",
    "      self.n_videos = n_videos\n",
    "      self.window_size = window_size\n",
    "      self.feature = feature\n",
    "      # Whether or not to include edge_attr in the dataset\n",
    "      self.include_edge_attr = include_edge_attr\n",
    "      # If true there will be 1024 links as opposed to 528\n",
    "      self.undirected_graphs = undirected_graphs\n",
    "      # Instantiate class to handle electrode positions\n",
    "      print('Using global connections' if add_global_connections else 'Not using global connections')\n",
    "      self.electrodes = Electrodes(add_global_connections, expand_3d = False)\n",
    "      super(DEAPDatasetEEGFeatures, self).__init__(root, transform, pre_transform)\n",
    "      self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "      \n",
    "\n",
    "  @property\n",
    "  def raw_dir(self):\n",
    "      return f'{self.root}/{self._raw_dir}'\n",
    "\n",
    "  @property\n",
    "  def processed_dir(self):\n",
    "      return f'{self.root}/{self._processed_dir}'\n",
    "\n",
    "  @property\n",
    "  def raw_file_names(self):\n",
    "      raw_names = [f for f in os.listdir(self.raw_dir)]\n",
    "      raw_names.sort()\n",
    "      return raw_names\n",
    "\n",
    "  @property\n",
    "  def processed_file_names(self):\n",
    "      if not os.path.exists(self.processed_dir):\n",
    "        os.makedirs(self.processed_dir)\n",
    "      file_name = f'{self.participant_from}-{self.participant_to}' if self.participant_from is not self.participant_to else f'{self.participant_from}'\n",
    "      return [f'deap_processed_graph.{file_name}_{self.feature}.dataset']\n",
    "\n",
    "  def process(self):\n",
    "        # Number of nodes per graph\n",
    "        n_nodes = len(self.electrodes.positions_3d)\n",
    "\n",
    "        if self.undirected_graphs:\n",
    "            source_nodes, target_nodes = np.repeat(np.arange(0,n_nodes),n_nodes), np.tile(np.arange(0,n_nodes),n_nodes)\n",
    "        else:\n",
    "            source_nodes, target_nodes = np.tril_indices(n_nodes,n_nodes)\n",
    "        \n",
    "        edge_attr = self.electrodes.adjacency_matrix[source_nodes,target_nodes]\n",
    "        \n",
    "        # Remove zero weight links\n",
    "        mask = np.ma.masked_not_equal(edge_attr, 0).mask\n",
    "        edge_attr,source_nodes,target_nodes = edge_attr[mask], source_nodes[mask], target_nodes[mask]\n",
    "\n",
    "        edge_attr, edge_index = torch.FloatTensor(edge_attr), torch.tensor([source_nodes,target_nodes], dtype=torch.long)\n",
    "        \n",
    "        # Expand edge_index and edge_attr to match windows\n",
    "        e_edge_index = edge_index.clone()\n",
    "        e_edge_attr = edge_attr.clone()\n",
    "        for i in range(58):\n",
    "            a = edge_index + e_edge_index.max() + 1\n",
    "            e_edge_index = torch.cat([e_edge_index,a],dim=1)\n",
    "            e_edge_attr = torch.cat([e_edge_attr,edge_attr],dim=0)\n",
    "\n",
    "        print(e_edge_index)\n",
    "        # List of graphs that will be written to file\n",
    "        data_list = []\n",
    "        pbar = tqdm(range(self.participant_from,self.participant_to+1))\n",
    "        for participant_id in pbar:\n",
    "            raw_name = [e for e in self.raw_file_names if str(participant_id).zfill(2) in e][0]\n",
    "            pbar.set_description(raw_name)\n",
    "            # Load raw file as np array\n",
    "            participant_data = scipy.io.loadmat(f'{self.raw_dir}/{raw_name}')\n",
    "            signal_data = torch.FloatTensor(participant_data['data'][:,:32,128*3:])\n",
    "            processed = []\n",
    "            for i, video in enumerate(signal_data[:self.n_videos,:,:]):\n",
    "                \n",
    "                # Differential entropy for each band\n",
    "                # node_features = process_video_de(video)\n",
    "\n",
    "                # Power spectral density for each channel\n",
    "                # node_features = scipy.signal.periodogram(video)[1]\n",
    "                node_features = process_video(video, feature=self.feature)\n",
    "                \n",
    "                # Raw signals \n",
    "                # node_features = video\n",
    "                \n",
    "                # Should we add MinMax/Z scaler?\n",
    "                data = Data(x=torch.FloatTensor(node_features),edge_attr=e_edge_attr,edge_index=e_edge_index, y=torch.FloatTensor([participant_data['labels'][i]])) if self.include_edge_attr else Data(x=torch.FloatTensor(node_features), edge_index=e_edge_index, y=torch.FloatTensor([participant_data['labels'][i]]))\n",
    "                data_list.append(data) \n",
    "               \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants used to define data paths\n",
    "ROOT_DIR = './'\n",
    "RAW_DIR = 'data/matlabPREPROCESSED'\n",
    "PROCESSED_DIR = 'data/graphProcessedData'\n",
    "\n",
    "# dataset = DEAPDatasetEEGFeatures(root= ROOT_DIR, raw_dir= RAW_DIR, processed_dir= PROCESSED_DIR, feature='de')\n",
    "# Subject-independent classificati\n",
    "# DEPENDING ON WHAT DATA IS USED THE NETWORK LEARNS BETTER OR WORSE.\n",
    "# SHOULD WE TRY TO HAVE A BALANCEd TRAINING SET?\n",
    "# dataset = dataset.shuffle()\n",
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 880 used for training, 220 validation and 180 testing\n",
    "splt_idx = 1100\n",
    "# splt_idx = 35\n",
    "\n",
    "# 85% used for train/val\n",
    "train_dataset = dataset[:splt_idx]\n",
    "test_dataset = dataset[splt_idx:]\n",
    "\n",
    "train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=128):\n",
    "        super(Model, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.gconv1 = GCNConv(in_channels, 256, aggr='add')\n",
    "        self.gconv2 = GCNConv(256, 128, aggr='add')\n",
    "        self.gconv3 = GCNConv(128, self.hidden_channels, aggr='add')\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(32*self.hidden_channels, 256, 1, stride=1)\n",
    "        self.conv2 = nn.Conv1d(256, 8, 1, stride=1)\n",
    "        \n",
    "        self.lin1 = nn.Linear(59*8,32)\n",
    "        self.lin2 = nn.Linear(32,1)\n",
    "#         self.lin3 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        bs = len(torch.unique(batch.batch))\n",
    "        x, edge_index = batch.x, batch.edge_index\n",
    "        \n",
    "\n",
    "#         x = x.reshape(-1,self.in_channels)\n",
    "#         print(x.shape)\n",
    "        x = self.gconv1(x, edge_index)\n",
    "#         x = torch.tanh(x)\n",
    "#         x = F.dropout(x, p=0.1, training=self.training)\n",
    "#         print(x.shape)\n",
    "#         raise 'err'\n",
    "        x = self.gconv2(x, edge_index)\n",
    "#         x = torch.tanh(x)\n",
    "        x = self.gconv3(x, edge_index)\n",
    "#         x = torch.tanh(x)\n",
    "#         x = x.reshape(bs,-1,32)\n",
    "        # batch size, graph, electrode, features\n",
    "        x = rearrange(x, '(b g e) f -> b (e f) g', b=bs, e=32)\n",
    "\n",
    "        \n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "#         print(x.shape)\n",
    "#         x = x.reshape(bs,-1,32)\n",
    "\n",
    "\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "\n",
    "        x = x.reshape(bs,-1)\n",
    "\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x.relu()\n",
    "        x = F.dropout(x, p=0.4, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "#         x.sigmoid()\n",
    "#         x = F.dropout(x, p=0.2, training=self.training)\n",
    "#         x = self.lin3(x)\n",
    "        x = x.view(-1)\n",
    "        x = x.sigmoid()\n",
    "#         print(x)\n",
    "#         x = x*10\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "\n",
    "model = Model(train_dataset[0].x.shape[1])     \n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model parameter count: {pytorch_total_params}')\n",
    "\n",
    "model = model.to(device)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=.1, rho=0.9, eps=1e-06, weight_decay=1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=1e-1, weight_decay=1e-3)\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr=1e-4, weight_decay=1e-2)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "# optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-2)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-3, lr_decay=1e-5, weight_decay=1e-2)\n",
    "\n",
    "# Instantiate optimizer\n",
    "# scheduler = StepLR(optimizer, step_size=20, gamma=0.7)\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "def train(loader, target = 0):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    right = 0\n",
    "    tot = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        y = (batch.y[:,target] > 5).float()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out,y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        right += torch.eq(out > .5, y > .5).sum().item()\n",
    "        tot += y.shape[0]\n",
    "    return np.array(losses).mean(), right/tot\n",
    "\n",
    "def test(loader,verbose=False, target = 0):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    right = 0\n",
    "    tot = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        y = (batch.y[:,target] > 5).float()\n",
    "        out = model(batch)\n",
    "        if verbose:\n",
    "            print(out,y)\n",
    "        loss = criterion(out,y)\n",
    "        losses.append(loss.item())\n",
    "        right += torch.eq(out > .5, y > .5).sum().item()\n",
    "        tot += y.shape[0]\n",
    "    return np.array(losses).mean(), right/tot\n",
    "\n",
    "best_val_loss = np.inf\n",
    "esp = 0\n",
    "MAX_ESP = 20\n",
    "\n",
    "BS = 4\n",
    "\n",
    "k_folds = 5\n",
    "k_fold_size = len(train_dataset)/k_folds\n",
    "current_fold = 0 # Ranges from 0 to k_folds-1\n",
    "\n",
    "target = 1 # Valence-Arousal-Dominance-Liking\n",
    "for epoch in range(1, 10000):    \n",
    "    # KFOLD train/val split     \n",
    "#     if epoch %1 == 0:\n",
    "#         current_fold = current_fold+1 if current_fold < k_folds-1 else 0\n",
    "    from_idx, to_idx = int(k_fold_size*current_fold), int(k_fold_size*(current_fold+1))\n",
    "    kf_val_data = train_dataset[from_idx:to_idx]\n",
    "    a = train_dataset[:from_idx]\n",
    "    b = train_dataset[to_idx:]\n",
    "    kf_train_data = a + b\n",
    "    train_loader = DataLoader(kf_train_data, batch_size=BS, shuffle=False)\n",
    "    val_loader = DataLoader(kf_val_data, batch_size=BS)\n",
    "        \n",
    "    # Training and validation\n",
    "    train_loss, train_acc = train(train_loader, target = target)\n",
    "    val_loss, val_acc = test(val_loader , target = target)\n",
    "    print(f'Epoch {epoch} - Kfold:{current_fold} ;t loss: {train_loss:.5f} ;t acc: {train_acc:.2f} ;v loss: {val_loss:.5f} ;v acc: {val_acc:.2f}')\n",
    "\n",
    "    # Early stopping and checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        esp = 0\n",
    "        torch.save(model.state_dict(),'./best_params') \n",
    "    else:\n",
    "        esp += 1\n",
    "        if esp >= MAX_ESP:\n",
    "            break\n",
    "            \n",
    "    if epoch % 20 == 0:\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "        loss, acc = test(test_loader, True)\n",
    "        print(f'Test loss: {loss} ; Test acc: {acc}')\n",
    "        \n",
    "#     scheduler.step()\n",
    "\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./best_params'))\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "loss, acc = test(train_loader, False,target=target)\n",
    "print(f'Train loss: {loss} ; Train acc: {acc}')\n",
    "loss, acc = test(val_loader, False,target=target)\n",
    "\n",
    "print(f'Val loss: {loss} ; Val acc: {acc}')\n",
    "loss, acc = test(test_loader, True,target=target)\n",
    "print(f'Test loss: {loss} ; Test acc: {acc}')\n",
    "\n",
    "# TODO: scheduler(?) Loss/acc records"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
