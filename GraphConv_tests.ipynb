{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The question is: \n",
    "### Are these equivalent?\n",
    "1. **Convolutions** -(then)-> **Window split**\n",
    "2. **Window split** -(then)-> **Convolutions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 8], x=[4, 2], y=[1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "node_features = torch.tensor([[2,3],[-1,0],[4,7],[5,9]]).float()\n",
    "source_nodes = torch.tensor([0,0,1,1,2,2,2,3])\n",
    "target_nodes = torch.tensor([1,2,0,2,0,1,3,2])\n",
    "edge_index = torch.stack([source_nodes,target_nodes])\n",
    "y = torch.tensor([1])\n",
    "\n",
    "# Graph object\n",
    "g = Data(x=node_features,edge_index=edge_index, y=y)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.6625,  0.6603],\n",
       "        [ 7.4924, -1.2082],\n",
       "        [10.9991,  1.8233],\n",
       "        [ 8.7213,  3.1475]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "conv = GraphConv(in_channels=2, out_channels=2, aggr='add', bias=False)\n",
    "conv(g.x.float(),g.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.3443,  0.4988],\n",
       "         [-0.0094, -0.0946]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.4386,  0.6717],\n",
       "         [ 0.2053,  0.3135]], requires_grad=True)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = []\n",
    "for p in (conv.parameters()):\n",
    "    params.append(p)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1850, -0.3028], grad_fn=<MvBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(params[0],node_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.6625,  0.6603],\n",
       "        [ 7.4924, -1.2082],\n",
       "        [10.9991,  1.8233],\n",
       "        [ 8.7213,  3.1475]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(g.x.float(),g.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 7.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature aggregation for neighbors to node 0\n",
    "neighbor_aggr = torch.sum(torch.stack([node_features[1],node_features[2]]),dim=0)\n",
    "neighbor_aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.6625, 0.6603], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(params[1],node_features[0]) + torch.matmul(params[0],neighbor_aggr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## They are equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphConv example\n",
    "![title](img/graph1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[8], edge_index=[2, 8], x=[4, 2], y=[1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "node_features = torch.tensor([[2,3],[-1,0],[4,7],[5,9]]).float()\n",
    "source_nodes = torch.tensor([0,0,1,1,2,2,2,3])\n",
    "target_nodes = torch.tensor([1,2,0,2,0,1,3,2])\n",
    "edge_index = torch.stack([source_nodes,target_nodes])\n",
    "edge_attr = torch.tensor([0.25,0.5,0.25,1,0.5,1,0.2,0.2]).float()\n",
    "y = torch.tensor([1])\n",
    "\n",
    "# Graph object\n",
    "g = Data(x=node_features,edge_index=edge_index,edge_attr=edge_attr, y=y)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2835, -0.9984],\n",
       "        [ 6.0066, -2.0781],\n",
       "        [ 0.6134, -0.6683],\n",
       "        [-1.1046, -0.1846]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "conv = GraphConv(in_channels=2, out_channels=2, aggr='add', bias=False)\n",
    "conv(g.x.float(),g.edge_index,g.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.5379,  0.5429],\n",
       "         [-0.1800, -0.1945]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.6213, -0.6001],\n",
       "         [-0.2394,  0.1588]], requires_grad=True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = []\n",
    "for p in (conv.parameters()):\n",
    "    params.append(p)\n",
    "params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
