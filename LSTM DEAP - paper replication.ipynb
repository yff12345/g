{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to replicate results from https://www.researchgate.net/profile/Salma-Alhagry/publication/320802497_Emotion_Recognition_based_on_EEG_using_LSTM_Recurrent_Neural_Network/links/5b39ff5a0f7e9b0df5e4cf26/Emotion-Recognition-based-on-EEG-using-LSTM-Recurrent-Neural-Network.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "from einops import reduce, rearrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants used to define data paths\n",
    "ROOT_DIR = './'\n",
    "RAW_DIR = 'data/matlabPREPROCESSED'\n",
    "PROCESSED_DIR = 'data/graphProcessedData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file_names = os.listdir(RAW_DIR)\n",
    "raw_file_names.sort()\n",
    "all_subjects = [scipy.io.loadmat(f'{RAW_DIR}/{name}') for name in raw_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [subject['data'] for subject in all_subjects]\n",
    "all_labels = [subject['labels'] for subject in all_subjects]\n",
    "labels = np.stack(all_labels)\n",
    "data = np.stack(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:,:,:32,128*3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = reduce(labels,'s v c -> (s v) c','mean')\n",
    "all_data = reduce(data,'s v c d -> (s v) c d','mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 40, 32, 7680), (1280, 32, 7680), (32, 40, 4), (1280, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, all_data.shape, labels.shape, all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = 2\n",
    "participant_data = data[participant][:,:,128*3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 40, 32, 7680)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "for participant_data in data:\n",
    "    for video in participant_data:\n",
    "        video = video.reshape(32,-1,128)\n",
    "        processed.append(video)\n",
    "#         processed.append(scipy.signal.periodogram(video)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1280, 32, 60, 128]), (1280, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = torch.FloatTensor(processed)\n",
    "# all_labels = labels[participant]\n",
    "all_data.shape, all_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.75\n",
    "target = 0 # valence\n",
    "split_idx = int(all_labels.shape[0]*train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = all_data[:split_idx], torch.FloatTensor(all_labels[:split_idx,target])\n",
    "test_x, test_y = all_data[split_idx:], torch.FloatTensor(all_labels[split_idx:,target])\n",
    "train_y = (train_y > 5).float()\n",
    "test_y = (test_y > 5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_train_split = 0.9\n",
    "split_idx = int(train_y.shape[0]*val_train_split)\n",
    "val_x, val_y = train_x[split_idx:], train_y[split_idx:]\n",
    "train_x, train_y = train_x[:split_idx], train_y[:split_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([864, 32, 60, 128]),\n",
       " torch.Size([96, 32, 60, 128]),\n",
       " torch.Size([320, 32, 60, 128]),\n",
       " torch.Size([864]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, val_x.shape, test_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(x,y) for x,y in zip(train_x,train_y)]\n",
    "val_data = [(x,y) for x,y in zip(val_x,val_y)]\n",
    "test_data = [(x,y) for x,y in zip(test_x,test_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BS, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=BS)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, in_channels,hidden_channels):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstms = nn.ModuleList([nn.LSTM(in_channels, hidden_channels, 4, dropout=0.05, batch_first=True).to(device) for i in range(32)])\n",
    "        self.lin1 = nn.Linear(hidden_channels*32,hidden_channels).to(device)\n",
    "        self.lin2 = nn.Linear(hidden_channels,1).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        hs = []\n",
    "        for i,lstm in enumerate(self.lstms):\n",
    "            o, (h,c) = lstm(x[:,i,:,:])\n",
    "            hs.append(h[-1])\n",
    "            \n",
    "        hs = torch.stack(hs)\n",
    "        x = hs.reshape(bs,-1)\n",
    "\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        return x.view(-1).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter count: 198673\n",
      "Epoch 1 ;t loss: 0.69544 ;t acc: 0.46 ;v loss: 0.69350 ;v acc: 0.46\n",
      "Epoch 2 ;t loss: 0.69242 ;t acc: 0.53 ;v loss: 0.69807 ;v acc: 0.47\n",
      "Epoch 3 ;t loss: 0.69182 ;t acc: 0.54 ;v loss: 0.70019 ;v acc: 0.48\n",
      "Epoch 4 ;t loss: 0.69090 ;t acc: 0.54 ;v loss: 0.70182 ;v acc: 0.48\n",
      "Epoch 5 ;t loss: 0.68949 ;t acc: 0.54 ;v loss: 0.70265 ;v acc: 0.48\n",
      "Epoch 6 ;t loss: 0.68883 ;t acc: 0.54 ;v loss: 0.70483 ;v acc: 0.48\n",
      "Epoch 7 ;t loss: 0.68911 ;t acc: 0.54 ;v loss: 0.70610 ;v acc: 0.48\n",
      "Epoch 8 ;t loss: 0.68975 ;t acc: 0.54 ;v loss: 0.70613 ;v acc: 0.48\n",
      "Epoch 9 ;t loss: 0.69104 ;t acc: 0.54 ;v loss: 0.70527 ;v acc: 0.48\n",
      "Epoch 10 ;t loss: 0.69046 ;t acc: 0.54 ;v loss: 0.70436 ;v acc: 0.48\n",
      "Epoch 11 ;t loss: 0.69029 ;t acc: 0.54 ;v loss: 0.70378 ;v acc: 0.48\n",
      "Epoch 12 ;t loss: 0.68959 ;t acc: 0.54 ;v loss: 0.70503 ;v acc: 0.48\n",
      "Epoch 13 ;t loss: 0.69013 ;t acc: 0.54 ;v loss: 0.70362 ;v acc: 0.48\n",
      "Epoch 14 ;t loss: 0.68934 ;t acc: 0.54 ;v loss: 0.70428 ;v acc: 0.48\n",
      "Epoch 15 ;t loss: 0.68979 ;t acc: 0.54 ;v loss: 0.70423 ;v acc: 0.48\n",
      "Epoch 16 ;t loss: 0.68919 ;t acc: 0.54 ;v loss: 0.70367 ;v acc: 0.48\n",
      "Epoch 17 ;t loss: 0.68989 ;t acc: 0.54 ;v loss: 0.70396 ;v acc: 0.48\n",
      "Epoch 18 ;t loss: 0.68914 ;t acc: 0.54 ;v loss: 0.70403 ;v acc: 0.48\n",
      "Epoch 19 ;t loss: 0.69004 ;t acc: 0.54 ;v loss: 0.70408 ;v acc: 0.48\n",
      "Epoch 20 ;t loss: 0.68969 ;t acc: 0.54 ;v loss: 0.70400 ;v acc: 0.48\n",
      "Epoch 21 ;t loss: 0.69011 ;t acc: 0.54 ;v loss: 0.70412 ;v acc: 0.48\n",
      "Epoch 22 ;t loss: 0.69000 ;t acc: 0.54 ;v loss: 0.70502 ;v acc: 0.48\n",
      "Epoch 23 ;t loss: 0.68911 ;t acc: 0.54 ;v loss: 0.70570 ;v acc: 0.48\n",
      "Epoch 24 ;t loss: 0.68976 ;t acc: 0.54 ;v loss: 0.70582 ;v acc: 0.48\n",
      "Epoch 25 ;t loss: 0.68971 ;t acc: 0.54 ;v loss: 0.70642 ;v acc: 0.48\n",
      "Epoch 26 ;t loss: 0.68995 ;t acc: 0.54 ;v loss: 0.70530 ;v acc: 0.48\n",
      "Epoch 27 ;t loss: 0.69028 ;t acc: 0.54 ;v loss: 0.70464 ;v acc: 0.48\n",
      "Epoch 28 ;t loss: 0.68885 ;t acc: 0.54 ;v loss: 0.70577 ;v acc: 0.48\n",
      "Epoch 29 ;t loss: 0.68932 ;t acc: 0.54 ;v loss: 0.70634 ;v acc: 0.48\n",
      "Epoch 30 ;t loss: 0.68970 ;t acc: 0.54 ;v loss: 0.70623 ;v acc: 0.48\n",
      "Epoch 31 ;t loss: 0.69052 ;t acc: 0.54 ;v loss: 0.70577 ;v acc: 0.48\n",
      "Epoch 32 ;t loss: 0.68981 ;t acc: 0.54 ;v loss: 0.70597 ;v acc: 0.48\n",
      "Epoch 33 ;t loss: 0.68966 ;t acc: 0.54 ;v loss: 0.70597 ;v acc: 0.48\n",
      "Epoch 34 ;t loss: 0.69127 ;t acc: 0.54 ;v loss: 0.70479 ;v acc: 0.48\n",
      "Epoch 35 ;t loss: 0.68965 ;t acc: 0.54 ;v loss: 0.70498 ;v acc: 0.48\n",
      "Epoch 36 ;t loss: 0.69096 ;t acc: 0.54 ;v loss: 0.70499 ;v acc: 0.48\n",
      "Epoch 37 ;t loss: 0.68950 ;t acc: 0.54 ;v loss: 0.70531 ;v acc: 0.48\n",
      "Epoch 38 ;t loss: 0.68897 ;t acc: 0.54 ;v loss: 0.70581 ;v acc: 0.48\n",
      "Epoch 39 ;t loss: 0.68902 ;t acc: 0.54 ;v loss: 0.70619 ;v acc: 0.48\n",
      "Epoch 40 ;t loss: 0.68981 ;t acc: 0.54 ;v loss: 0.70585 ;v acc: 0.48\n",
      "Epoch 41 ;t loss: 0.68955 ;t acc: 0.54 ;v loss: 0.70583 ;v acc: 0.48\n",
      "Epoch 42 ;t loss: 0.68919 ;t acc: 0.54 ;v loss: 0.70615 ;v acc: 0.48\n",
      "Epoch 43 ;t loss: 0.68837 ;t acc: 0.54 ;v loss: 0.70706 ;v acc: 0.48\n",
      "Epoch 44 ;t loss: 0.69012 ;t acc: 0.54 ;v loss: 0.70640 ;v acc: 0.48\n",
      "Epoch 45 ;t loss: 0.68950 ;t acc: 0.54 ;v loss: 0.70621 ;v acc: 0.48\n",
      "Epoch 46 ;t loss: 0.68967 ;t acc: 0.54 ;v loss: 0.70627 ;v acc: 0.48\n",
      "Epoch 47 ;t loss: 0.69014 ;t acc: 0.54 ;v loss: 0.70614 ;v acc: 0.48\n",
      "Epoch 48 ;t loss: 0.68959 ;t acc: 0.54 ;v loss: 0.70657 ;v acc: 0.48\n",
      "Epoch 49 ;t loss: 0.68969 ;t acc: 0.54 ;v loss: 0.70651 ;v acc: 0.48\n",
      "Epoch 50 ;t loss: 0.68997 ;t acc: 0.54 ;v loss: 0.70680 ;v acc: 0.48\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "model = Model(all_data.shape[-1],hidden_channels=8)     \n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model parameter count: {pytorch_total_params}')\n",
    "\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=.1, rho=0.9, eps=1e-06, weight_decay=1e-5)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-1, weight_decay=1e-3)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=.05, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=True)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01, weight_decay=1e-6)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    losses = []\n",
    "    right = 0\n",
    "    tot = 0\n",
    "    for x,y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        loss = criterion(out,y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        right += torch.eq(out > 0.5, y > 0.5).sum().item()\n",
    "        tot += y.shape[0]\n",
    "    return np.array(losses).mean(), right/tot\n",
    "\n",
    "def test(loader,verbose=False):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    right = 0\n",
    "    tot = 0\n",
    "    for x,y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        if verbose:\n",
    "            print(out,y)\n",
    "        right += torch.eq(out > 0.5, y > 0.5).sum().item()\n",
    "        tot += y.shape[0]\n",
    "        loss = criterion(out,y)\n",
    "        losses.append(loss.item())\n",
    "    return np.array(losses).mean(), right/tot\n",
    "\n",
    "best_val_loss = np.inf\n",
    "esp = 0\n",
    "MAX_ESP = 50\n",
    "for epoch in range(1, 1000):\n",
    "    train_loss, train_acc = train()\n",
    "    val_loss, val_acc = test(val_loader)\n",
    "    if val_loss <= best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        esp = 0\n",
    "    else:\n",
    "        esp += 1\n",
    "        if esp >= MAX_ESP:\n",
    "            break\n",
    "#     if epoch%5 == 0:\n",
    "    print(f'Epoch {epoch} ;t loss: {train_loss:.5f} ;t acc: {train_acc:.2f} ;v loss: {val_loss:.5f} ;v acc: {val_acc:.2f}')\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = test(test_loader)\n",
    "print(f'Test loss: {loss} ; Test acc: {acc}')\n",
    "\n",
    "# TODO: esp, kfold val , scheduler(?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
